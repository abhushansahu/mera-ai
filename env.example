# =============================================================================
# Mera AI - Environment Configuration
# =============================================================================
#
# This file contains all environment variables used by the Mera AI application.
# Copy this file to .env and fill in your actual values:
#
#   cp env.example .env
#   # Then edit .env with your actual API keys and configuration
#
# IMPORTANT: This configuration assumes self-hosted services (PostgreSQL, Mem0, Langfuse)
# Start self-hosted services with: docker-compose up -d
#
# =============================================================================
# REQUIRED CONFIGURATION - Application will NOT start without these
# =============================================================================

# -----------------------------------------------------------------------------
# OpenRouter API Configuration (External Service)
# -----------------------------------------------------------------------------
# OpenRouter provides access to multiple LLM models through a single API.
# Get your API key at: https://openrouter.ai/
# Required: YES - Application will fail to start without this

OPENROUTER_API_KEY=your_openrouter_api_key_here

# OpenRouter Base URL
# Default: https://openrouter.ai/api/v1
# Only change this if using a custom OpenRouter endpoint
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Default LLM Model
# Default: openai/gpt-4o-mini
# This model will be used when no specific model is requested
# See available models at: https://openrouter.ai/models
DEFAULT_MODEL=openai/gpt-4o-mini


# -----------------------------------------------------------------------------
# Database Configuration (Self-Hosted PostgreSQL)
# -----------------------------------------------------------------------------
# PostgreSQL database connection string for the main application database.
# The database is self-hosted via Docker Compose.
# Required: YES - Application will fail to start without this
#
# Format: postgresql+psycopg2://user:password@host:port/database
# Default values match docker-compose.yml configuration

DATABASE_URL=postgresql+psycopg2://ai_user:ai_password@localhost:5432/ai_assistant


# -----------------------------------------------------------------------------
# Chroma Memory Service Configuration
# -----------------------------------------------------------------------------
# Chroma provides persistent memory for the AI assistant via vector embeddings.
# Required: NO - Chroma uses embedded mode by default
#
# Option 1: Embedded Mode (Default, Recommended)
# Chroma runs embedded in the application process
# Default persist directory: ./chroma_db
CHROMA_PERSIST_DIR=./chroma_db
CHROMA_COLLECTION_NAME=memories

# Option 2: Client-Server Mode (Optional)
# If you prefer to run Chroma as a separate server:
# 1. Start Chroma server separately
# 2. Set CHROMA_HOST and CHROMA_PORT below
# CHROMA_HOST=
# CHROMA_PORT=8000


# =============================================================================
# OPTIONAL CONFIGURATION - Application will run without these
# =============================================================================

# -----------------------------------------------------------------------------
# LangSmith Observability (Cloud Service)
# -----------------------------------------------------------------------------
# LangSmith provides observability, tracing, and monitoring for LLM applications.
# LangSmith is a cloud service provided by LangChain.
# Optional: Application will run without LangSmith, but observability will be disabled
#
# Setup Instructions:
# 1. Sign up for LangSmith at: https://smith.langchain.com/
# 2. Create an API key in your LangSmith dashboard
# 3. Copy your API key below
# 4. Optionally set a project name (default: "mera-ai")

# LangSmith API Key
# Get this from your LangSmith dashboard: https://smith.langchain.com/settings
# Leave empty if you don't want to use LangSmith observability
LANGSMITH_API_KEY=

# LangSmith Project Name
# Default: mera-ai
# This groups your traces in the LangSmith dashboard
LANGSMITH_PROJECT=mera-ai

# LangSmith API URL
# Default: https://api.smith.langchain.com
# Only change if using a custom LangSmith instance
LANGSMITH_API_URL=https://api.smith.langchain.com

# LangSmith Tracing V2
# Default: true
# Enable LangSmith tracing v2 (recommended)
LANGSMITH_TRACING_V2=true


# -----------------------------------------------------------------------------
# Obsidian Integration (External/Local Application)
# -----------------------------------------------------------------------------
# Obsidian provides a knowledge vault for storing and retrieving context.
# Obsidian runs locally on your machine (not in Docker).
# Optional: Application will run without Obsidian integration
#
# Setup Instructions:
# 1. Install Obsidian: https://obsidian.md/
# 2. Install the REST API plugin: https://github.com/coddingtonbear/obsidian-web
# 3. Configure the plugin to run on the port specified below
# 4. Get your REST API token from the plugin settings

# Obsidian REST API URL
# Default: http://localhost:27124
# Change if your Obsidian REST API runs on a different port
OBSIDIAN_REST_URL=http://localhost:27124

# Obsidian REST API Token
# Get this from your Obsidian REST API plugin settings
# Leave empty if you don't want to use Obsidian integration
OBSIDIAN_REST_TOKEN=

# Obsidian Vault Path (for LlamaIndex indexing)
# Path to your Obsidian vault directory
# If set, the system will use LlamaIndex for enhanced retrieval
# If not set, falls back to REST API integration
OBSIDIAN_VAULT_PATH=


# -----------------------------------------------------------------------------
# CORS Configuration
# -----------------------------------------------------------------------------
# CORS (Cross-Origin Resource Sharing) allows web browsers to make requests
# from different origins (domains) to your API.
# Optional: Defaults to allowing all origins (*) for development

# CORS Allowed Origins
# Comma-separated list of allowed origins for CORS requests
# Examples:
#   - "*" (default) - Allow all origins (development only, not recommended for production)
#   - "http://localhost:3000,http://localhost:3001" - Allow specific origins
#   - "https://yourdomain.com,https://www.yourdomain.com" - Production origins
# Leave empty to allow all origins (development mode)
CORS_ORIGINS=


# -----------------------------------------------------------------------------
# Orchestrator Selection
# -----------------------------------------------------------------------------
# Choose between LangGraph (default) and LangChain orchestrators.
# Optional: Application defaults to LangGraph if not set.
#
# USE_LANGCHAIN_ORCHESTRATOR: Set to "true" to use LangChain orchestrator
# Default: false (uses LangGraph orchestrator)
# USE_LANGCHAIN_ORCHESTRATOR=false


# =============================================================================
# DEPLOYMENT SCENARIOS
# =============================================================================
#
# The configuration above assumes a self-hosted setup. Here are alternative
# configurations for different deployment scenarios:
#
# -----------------------------------------------------------------------------
# Scenario 1: Fully Self-Hosted (Default/Recommended)
# -----------------------------------------------------------------------------
# - PostgreSQL: Self-hosted via Docker (DATABASE_URL points to localhost:5432)
# - Chroma: Embedded mode (CHROMA_PERSIST_DIR=./chroma_db)
# - Langfuse: Self-hosted via Docker (LANGFUSE_HOST=http://localhost:3000)
# - Obsidian: Local application (optional)
#
# This is the default configuration and requires:
#   docker-compose up -d
#
# -----------------------------------------------------------------------------
# Scenario 2: Production Deployment
# -----------------------------------------------------------------------------
# For production, you should:
# 1. Change all default passwords (DATABASE_URL, MEM0_API_KEY)
# 2. Use strong, unique API keys
# 3. Set up proper network security (firewall, VPN, etc.)
# 4. Use environment-specific values (dev/staging/prod)
# 5. Never commit .env file to version control
#
# -----------------------------------------------------------------------------
# Scenario 3: Development Without Optional Services
# -----------------------------------------------------------------------------
# For development, you can run without optional services:
# - Leave LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY empty
# - Leave OBSIDIAN_REST_TOKEN empty
# The application will run but without observability and Obsidian integration
#
# =============================================================================
# TROUBLESHOOTING
# =============================================================================
#
# If the application fails to start:
# 1. Check that all REQUIRED variables are set
# 2. Verify API keys are valid and not expired
# 3. Ensure Docker services are running: docker-compose ps
# 4. Check service logs: docker-compose logs [service-name]
# 5. Verify database connection: psql -h localhost -U ai_user -d ai_assistant
# 6. Test Mem0 health: curl http://localhost:8001/health
# 7. Test Langfuse health: curl http://localhost:3000/api/public/health
#
# Common Issues:
# - "OPENROUTER_API_KEY is required": Set a valid OpenRouter API key
# - "DATABASE_URL is required": Set the PostgreSQL connection string
# - Chroma uses embedded mode by default, no configuration required
# - Langfuse ZodError: This is handled automatically by the application
#
# =============================================================================
